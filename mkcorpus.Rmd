---
title: "Make the corpus"
author: "JBaker"
date: "September 5, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Corpus Construction

The intent of this document is to illustrate the use of the toolset in the NWPT to create corpus, n-grams and frequency and, the prediction model.

### Basic cleaning

Apply the basic cleaning routine to the corpus and save the contents in the local file system with the "./clean" prefix. Following the cleaning, dice the corpus into "train", "test", and "valid" data sets, each representing (70%, 20%, 10% - respectively) of the total corpus. dicecorpus() also divides the "train" dataset into 5 chunks per data type - yielding 15 files to process to build the model. This division of the input data is done to reduce the memory footprint during the n-gram creation.

```{r getclean, cache=TRUE, eval=FALSE}
source("sampleCorpus.R")
source("CC/n-grams.R")
getclean()
dicecorpus()
```

### Make the n-grams

Process the "./train*" portion of the corpus and make the n-grams. Strip off the single occurrence n-grams. The make the n-gram a set of named tokens. Save the resulting set of n-grams.

```{r mkngrams, cache=TRUE, eval=FALSE}
udt <- trainProcess(1)
print("Unigrams complete")
bdt <- trainProcess(2)
print("Bigrams complete")
tdt <- trainProcess(3)
print("Trigrams complete")
qdt <- trainProcess(4)
print("Quadgrams complete")

# strip the single occurrence n-grams and tokenize the output
source("CC/mkmodel.R")
ut <- unimodel(udt$freq > 1])
udt <- NULL

bt <- bimodel(bdt$freq > 1])
bdt <- NULL

tt <- trimodel(tdt$freq > 1])
tdt <- NULL

qt <- quadmodel(qdt$freq > 1])
qdt <- NULL
gc()

save(ut, bt, tt, qt, file="ngrams.RData")
```
